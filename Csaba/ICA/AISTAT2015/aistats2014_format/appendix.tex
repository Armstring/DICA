%!TEX root =  DICA.tex
\onecolumn

\section{Appendix}
\label{sec:Appendix}

\subsection{Proof of Lemma \ref{prop:denoise}}
Let $M = \E_{X\sim \nu_T^{(s)}}[X^{\otimes 4}] - $ as a tensor of dimension 4. 
Note that 
\begin{align*}
& \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX+Y)^{\otimes 4}]\\
 = & \,\E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 4}] \\
& \quad+ \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX)^{\otimes 3}\otimes Y + (AX)^{\otimes 2}\otimes Y\otimes (AX) + (AX)\otimes Y\otimes (AX)^{\otimes 2} + Y\otimes (AX)^{\otimes 3}] \\
& \quad+ E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [ (AX)^{\otimes 2}\otimes Y^{\otimes 2} + (AX)\otimes Y\otimes (AX)\otimes Y + (AX)\otimes Y^{\otimes 2}\otimes (AX)]\\
& \quad+  E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [ (Y)^{\otimes 2}\otimes (AX)^{\otimes 2} + (Y)\otimes (AX)\otimes Y\otimes (AX) + Y\otimes (AX)^{\otimes 2}\otimes Y] \\
& \quad+ E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [[Y^{\otimes 3}\otimes (AX) + Y^{\otimes 2}\otimes (AX)\otimes Y + Y\otimes (AX)\otimes Y^{\otimes 2} + (AX)\otimes Y^{\otimes 3}] \\
& \quad+ \E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 4}],
\end{align*}
and 
\begin{align*}
\E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX+Y)^{\otimes 2}]= & \, \E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 2}] + \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}}[(AX)\otimes Y + Y\otimes (AX)] + \E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 2}]\\
 \le & \E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 2}] + \E_{X\sim \nu_t^{(s)}}[(AX)]\otimes \E_{Y\sim \nu_t^{(\epsilon)}}[Y] \\
 & \quad  + \E_{Y\sim \nu_t^{(\epsilon)}}[Y] \otimes E_{X\sim \nu_t^{(s)}}[(AX)] + \E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 2}] + \frac{2L}{\sqrt{t}} \boldsymbol{1}^{\otimes 2}.
\end{align*}
To calculate $\E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX+Y)^{\otimes 4}] - 3\left( \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX+Y)^{\otimes 2}]\right)^2 $, we decompose it to several parts.
\begin{align*}
 & \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX+Y)^{\otimes 4}] - 3\left( \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX+Y)^{\otimes 2}]\right)^2 \\
 = & \,\left[\E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 4}] - 3\left(\E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 2}]\right)^2 \right]+ K_1 + K2 +K_3 \\
 & + \left[\E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 4}] - 3\left(\E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 2}]\right)^2 \right].
\end{align*}
Here 
\begin{align*}
K1 = & \, \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}} [(AX)^{\otimes 3}\otimes Y + (AX)^{\otimes 2}\otimes Y\otimes (AX) + (AX)\otimes Y\otimes (AX)^{\otimes 2} + Y\otimes (AX)^{\otimes 3}] \\
& \quad - 3\big(
\E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 2}] \otimes \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}}[(AX)\otimes Y + Y\otimes (AX)]\\
& \quad  + \E_{(X,Y)\sim \nu_t^{(s,\epsilon)}}[(AX)\otimes Y + Y\otimes (AX)] \otimes \E_{X\sim \nu_t^{(s)}}[(AX)^{\otimes 2}] 
\big) 
\end{align*}
Note that $\| \left[\E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 4}] - 3\left(\E_{Y\sim \nu_t^{(\epsilon)}}[Y^{\otimes 2}]\right)^2 \right]\|_F \le \frac{L}{\sqrt{t}}$.
Also, $\nabla^2f_{\nu_T^{(x)}}(\eta)$ ($\nabla^2f_{\nu_T^{(As)}}(\eta)$, respectively) is the matrix generated by marginalizing 2 dimensions of the tensor $\E_{(X,Y)\sim \nu_T^{(s,\epsilon)}} [(AX+Y)^{\otimes 4}] - 3\left( \E_{(X,Y)\sim \nu_T^{(s,\epsilon)}} [(AX+Y)^{\otimes 2}]\right)^2 $ ($ \E_{X\sim \nu_T^{(s)}}[(AX)^{\otimes 4}] - 3\left(\E_{X\sim \nu_T^{(s)}}[(AX)^{\otimes 2}]\right)^2$, respectively) on the directions $\eta$.
Thus, it remains to bound 


Note that $\|As\|_2 \le \sqrt{d}\sigma_{\max}(A)C$, and $\vert \eta^{\top}As\vert \le \sqrt{d}L_{\eta}\sigma_{\max}(A)C$.

Thus 
We treat $\nabla^2f_{\nu_t^{(x)}}(\eta)$ as a flattened tensor by margin
Note that 

Given $\eta \le L_{\eta}$, we have can bound 

\subsection{Proof of Theorem \ref{thm:efficiency}}
\label{subsec:ProofEfficiency}
The following result is proven by \citet{DHsu2012}:
\begin{thm}[\citet{DHsu2012}, Theorem~4]
Assume $A$ is nonsingular. 
Let $m_4,m_2:\real^d \ra \real$ be defined by Equation \eqref{eq:momnent} with respect to the product distribution $\mu$,
	while $f: \real^d \ra \real$ be defined by Equation \eqref{eq:funcf}.
Let $\phi,\psi\in \real^d$ be vectors from the unit sphere of $\real^d$. Then, 
	the matrix
\begin{equation}
\label{eq:M}
M =(\nabla^2f(\phi))(\nabla^2f(\psi))^{-1} 
\end{equation}
can be written in the diagonal form
\begin{equation}
\label{eq:M2}
M = A 
\left(
\begin{array}{ccc}
\lambda_1 & & \\ %\left(\frac{\phi^{\top}A_1}{\psi^{\top}A_1}\right)^2 & &\\
    & \ddots & \\
    & & \lambda_d %\left(\frac{\phi^{\top}A_d}{\psi^{\top}A_d}\right)^2\\
\end{array} 
\right) 
A^{-1},
\end{equation}
where $\lambda_i = \left(\frac{\phi^{\top}A_i}{\psi^{\top}A_i}\right)^2$.
\end{thm}

In our deterministic setting, $\nabla^2f(\phi)$ in the above theorem will need to be replaced by $\nabla^2f_{\mu}(A^{\top}\eta)$.
It follows from this theorem that 
if $\phi,\psi$ are chosen independently from the uniform distribution on the unit sphere of $\real^d$, with probability one,
the eigenvalues of  $M$ are all distinct and the corresponding eigenvectors
determine the rows of $A$ up to permutation and scaling.
%Now since we have a product measure $\mu$ that $\nu_T^{(s)}$ is close to, we can treat $s(t)$ is an empirical instance from the distribution $\mu$.  

The following lemma bounds $\|\nabla^2 f_{\mu}(\eta) - \nabla^2 \widehat{f}(\eta) \|_2$ by $\xi$:
\begin{lemma}
\label{lem:nablavariation}
\[
\|\nabla^2 f_{\mu}(A^{\top}\eta) - \nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta)  \|_2 \le \|\nabla^2 f_{\mu}(\eta) - \nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta)  \|_F\le  \|\eta\|_2^2  d^5 A_{(2,\max)}^2A_{\max}^2\xi.
\]
Thus, 
\[
\|\nabla^2 f_{\mu}(A^{\top}\eta) - \nabla^2\widehat{f}(\eta)\|_2 \le  \|\eta\|_2^2  d^5 A_{(2,\max)}^2A_{\max}^2\xi + P.
\]
\end{lemma}
\begin{proof}
Without loss of generality assume $\|\eta\|_2 = 1$.
Note that  
\[
\nabla^2 f_{\mu}(\eta) = G_1(\eta) - G_2(\eta) -2G_3(\eta),
\]
and 
\[
\nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta) =\widehat{G_1}(\eta) - \widehat{G_2}(\eta) -2\widehat{G_3}(\eta),
\]
where 
\begin{align*}
& G_1(\eta) = \int (\eta^{\top}As)^2Ass^{\top}A^{\top}\,d\mu(s); \\
& G_2(\eta) = \int (\eta^{\top}As)^2\,d\mu(s) \int Ass^{\top}A^{\top} \,d\mu(s); \\
& G_3(\eta) = \Big(\int (\eta^{\top}As)As\,d\mu(s)\Big)\Big(\int (\eta^{\top}As)As\,d\mu(s)\Big)^{\top}. \\
&\widehat{ G_1}(\eta) = \frac1n\sum_{k=1}^{n} \big(\eta^{\top}As(k)\big)^2As(k)s(k)^{\top}A^{\top} = \int (\eta^{\top}As)^2Ass^{\top}A^{\top}\,d\nu_T(s); \\
& \widehat{G_2}(\eta) = \frac{1}{n^2}\sum_{k=1}^{n} \big(\eta^{\top}As(k)\big)^2 \sum_{k=1}^{n}As(k)s(k)^{\top}A^{\top} = \int (\eta^{\top}As)^2\,d\nu_T(s) \int Ass^{\top}A^{\top} \,d\nu_T(s); \\
& \widehat{G_3}(\eta) = \frac{1}{n^2}\Big(\sum_{k=1}^{n} \big(\eta^{\top}As(k)\big)As(k)\Big) \Big(\sum_{k=1}^{n} \big(\eta^{\top}As(k)\big)As(k)\Big)^{\top} = \Big(\int (\eta^{\top}As)As\,d\nu_T(s)\Big)\Big(\int (\eta^{\top}As)As\,d\nu_T(s)\Big)^{\top}.
\end{align*}

%Without loss of generality, assume $ \|\eta\|_2 = 1$.
Note that all the integral functions of $G_i(\eta)$ or $\widehat{G_i}(\eta)$ are matrices of polynomials in $x$. Thus, we only need to bound its coefficients.
%Also, since $|b_1b_2b_3b_4| \le \frac14(b_1^4+b_2^4+b_3^4+b_4^4)$, we only need to upper bound the coefficients of $x_i^4$. 
Note that 
\[
\left(G_1\right)_{i,j} = \int (\sum_t \eta^{\top}A_ts_t)^2\sum_t A_{i,t}s_t \sum_t A_{j,t}s_t d\mu(s).
\]
Thus, the coefficient of the term $s_{t_1}s_{t_2}s_{t_3}s_{t_4}$ is $\eta^{\top}A_{t_1}\eta^{\top}A_{t_2}A_{i,t_3}A_{j,t_4}$, 
which is bounded by $\max_i |\eta^{\top} A_i|^2 A_{\max}^2 \le A_{(2,\max)}^2A_{\max}^2$. 
Thus,
\[
\left| (G_1)_{i,j} - (\widehat{G_1})_{i,j} \right| \le d^4  A_{(2,\max)}^2A_{\max}^2D_4(\mu, \nu_T).
\]

Similarly, 
\[
\left| \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\mu(s) - \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \le d^2 A_{\max}^2 D_2(\mu,\nu_T)
\]
 and 
\[
\left| \int (\eta^{\top}As)^2\,d\mu(s) -\int (\eta^{\top}As)^2\,d\nu_T(s) \right| \le d^2 A_{(2,\max)}^2 D_2(\mu,\nu_T).
\]
Also note that $ \left| \int (\eta^{\top}As)^2\,d\mu(s) \right| \le d^2A_{(2,\max)}^2 C^2$, and
$\left| \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \le d^2A_{\max}^2 C^2$.
Now consider the difference between $G_2$ and $\widehat{G_2}$. 
\begin{align*}
& \left| (G_2)_{i,j} - (\widehat{G_2})_{i,j} \right| \\
=\, & \left| \int (\eta^{\top}As)^2\,d\mu(s) \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\mu(s)  - 
\int (\eta^{\top}As)^2\,d\nu_T(s) \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \\
\le \, & \left| \int (\eta^{\top}As)^2\,d\mu(s) \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\mu(s)  - 
\int (\eta^{\top}As)^2\,d\mu(s) \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \\ 
& \quad + \left| \int (\eta^{\top}As)^2\,d\mu(s) \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s)  - 
\int (\eta^{\top}As)^2\,d\nu_T(s) \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \\
\le\, & \left| \int (\eta^{\top}As)^2\,d\mu(s) \right| \left|\int A_{i:}ss^{\top}A_{j:}^{\top} \,d\mu(s) - \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \\
& \quad + \left| \int (\eta^{\top}As)^2\,d\mu(s) -\int (\eta^{\top}As)^2\,d\nu_T(s) \right| \left| \int A_{i:}ss^{\top}A_{j:}^{\top} \,d\nu_T(s) \right| \\
\le\, & 2 d^4  A_{(2,\max)}^2A_{\max}^2C^2D_2(\mu, \nu_T).
\end{align*}
Similarly,
\[
\left| (G_3)_{i,j} - (\widehat{G_3})_{i,j} \right| \le 2 d^4  A_{(2,\max)}^2A_{\max}^2C^2D_2(\mu, \nu_T).
\]
Thus for any $1\le i,j\le d$,
\begin{align*}
\left|\left(\nabla^2 f_{\mu}(A^{\top}\eta) \right)_{i,j} - \left(\nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta) \right)_{i,j} \right| 
\le 
d^4  A_{(2,\max)}^2A_{\max}^2\left( 6C^2D_2(\mu, \nu_T) + D_4(\mu, \nu_T)\right).
\end{align*}
Therefore, 
\[
\|\nabla^2 f_{\mu}(A^{\top}\eta) - \nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta)  \|_2 \le \|\nabla^2 f_{\mu}(A^{\top}\eta) - \nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta) \|_F \le d^5  A_{(2,\max)}^2A_{\max}^2\left( 6C^2D_2(\mu, \nu_T) + D_4(\mu, \nu_T)\right).
\]
Lastly, combining with Proposition \ref{prop:denoise}, 
\[
\|\nabla^2 f_{\mu}(A^{\top}\eta) - \nabla^2\widehat{f}(\eta)\|_2 \le \|\nabla^2 f_{\mu}(A^{\top}\eta) - \nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta)\|_2 + \| \nabla^2 \widehat{f_{\nu_T^{(As)}}}(\eta) - \nabla^2\widehat{f}(\eta)\|_2 \le \|\eta\|_2^2  d^5 A_{(2,\max)}^2A_{\max}^2\xi + P.
\]
\end{proof}
Before we can prove the theorem, we need to prove some lemmas.
The following lemma shows that a small perturbation of $M$ will only result in a small variation of its eigenvectors, at least under some mild regularity conditions.
\begin{lemma}
\label{lem:eigenvectorvariation}
Denote $\widehat{M} = M+E$ be a perturbation of matrix $M$, where $M$ is defined in  \eqref{eq:M2}. 
Assume $\widehat{M}$ has distinct eigenvalues. 
If $\gamma_A > 4 \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2$, and $\min_{i,j:i\neq j} \|A_i - A_j\|_2 > \frac{8}{\gamma_A}\frac{\sigma_{\max}^2(A)}{\sigma_{\min}(A) } \|E\|_2$, then there exist a permutation $\pi$ and constants $\{c_1,\ldots,c_d\}$, such that 
\[
\max_{1\le k\le d} \| c_1\widehat{A}_{\pi(k)} - A_k\|_2 \le 4  \frac{\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A) } \|E\|_2\,,
\]
and therefore
\[
\sum_{k=1}^{d}\| c_1\widehat{A}_{\pi(k)} - A_k\|_2 \le 4d  \frac{\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A)} \|E\|_2\,,
\]
where $\widehat{A}$ is the matrix of eigenvectors of $\widehat{M}$. 
\end{lemma}
\begin{proof}
For $1\le k\le d$, assume 
\[
A_{(k)}^{-1} E A_{(k)} =  
\left(
\begin{array}{cc}
F_{1k} & F_{2k}\\
F_{3k} & F_{4k} \\
\end{array} 
\right), 
\]
where $A_{(k)}$ is the matrix $(A_k, A_1, \cdots, A_{k-1}, A_{k+1}, \cdots, A_d)$.
Let $\gamma_k = \|F_{3k}\|_2$, $\eta_k = \|F_{3k}\|_2$, and 
\[
\delta_k = \min_{j: j\neq k} 
\left\vert \left(\frac{\phi^{\top}A_k}{\psi^{\top}A_k}\right)^2 -\left( \frac{\phi^{\top}A_j}{\psi^{\top}A_j}\right)^2 \right\vert - \|F_{1k}\|_2 - \|F_{4k}\|_2\,.
\]
Note that by definition, $\gamma_k = \|F_{3k}\|_2\le\|A_{(k)}^{-1}EA_{k}\|_2\le\frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2$,
 $\eta_k = \|F_{2k}\|_2\le\|(A^{-1})_kEA_{(k)}\|_2\le\frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2$, 
 and $\|F_{1k}\|_2,\|F_{4k}\|_2\le\|A_{(k)}^{-1} E A_{(k)}\|_2\le\frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2$. 
 Thus,
\begin{align*}
\delta_k & = \min_{j:j\neq k} 
	\left\vert \left(\frac{\phi^{\top}A_k}{\psi^{\top}A_k}\right)^2 - \left(\frac{\phi^{\top}A_j}{\psi^{\top}A_j}\right)^2 \right\vert - \|F_{1k}\|_2 - \|F_{4k}\|_2\\
	& \ge \min_{j:j\neq k} \left\vert \left(\frac{\phi^{\top}A_k}{\psi^{\top}A_k}\right)^2 - \left(\frac{\phi^{\top}A_j}{\psi^{\top}A_j}\right)^2 \right\vert - 2 \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2\\
	& \ge  \gamma_A -  2 \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2 \\
	& >  2 \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}\|E\|_2 >0,
\end{align*}
and $\delta_k^2 > 4\gamma_k\eta_k$. 
Therefore, by Theorem 2.8, Chapter V of \citep{stewart1990matrix}, there exist a unique vector $v$ satisfying $\|v\|_2\le 2\frac{\gamma_k}{\delta_k}$ such that there exists one of a eigenvector $\widehat{A_k}$ of $\widehat{M}$ satisfying
 \[
 \|\widehat{A_k} - A_k\|_2 \le \|A_{ck}\|_2 \|v\|_2 \le 2\sigma_{\max}(A)\frac{\gamma_k}{\delta_k}
 \le 
 \frac{4\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A) } \|E\|_2,
 \]
 where $A_{ck}$ is the $d\times (d-1)$ matrix $(A_1,\ldots,A_{k-1}, A_{k+1},\ldots,A_d)$.
 By condition, for $i\neq j$,  $\frac{8\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A) } \|E\|_2 < \|A_i - A_j\|_2\le \|A_i - \widehat{A_i}\|_2 + \|A_j - \widehat{A_i}\|_2$, thus $\widehat{A_i} \neq \widehat{A_j}$.  Summing up the upper bound gets the result. 
\end{proof}
The next lemma shows that $\widehat{X}^{-1}$ is close to $X^{-1}$ with respect to  matrix $2$-norm.
\begin{lemma}
\label{lem:inversevariation}
If non-singular matrix $\widehat{X} = X+E$ satisfying that $\sigma_{\min}(X)\ge2\|E\|_2$, then $\|\widehat{X}^{-1}\|_2 \le \frac{2}{\sigma_{\min}(X)}$, and $\|\widehat{X}^{-1} - X^{-1} \|_2 \le \frac{2}{\sigma_{\min}^2(X)}\|E\|_2$.
\end{lemma} 
\begin{proof}
Note that $\|\widehat{X}^{-1}\|_2$ is the inverse of the minimal singular value of $\widehat{X}$. Also, 
\[
 \min_{v:\|v\|_2=1} \|\widehat{X}v\|_2 = \min_{v:\|v\|_2=1}\|(X+E)v\|_2 \ge \min_{v:\|v\|_2=1} \|Xv\|_2 - \|Ev\|_2 \ge \sigma_{\min}(X) - \|E\|_2.
\]
So $\|\widehat{X}^{-1}\|_2 \le \frac{1}{\sigma_{\min}(X) - \|E\|_2} \le \frac{2}{\sigma_{\min}(X)}$. Moreover,
\begin{align*}
\|\widehat{X}^{-1} - X^{-1} \|_2 \le \|X^{-1}\|_2\|\widehat{X}^{-1}\|_2\|\widehat{X} - X\|_2
\le \frac{2}{\sigma_{\min}^2(X)}\|E\|_2.
\end{align*}
\end{proof}
Now we can estimate the variance between $XY^{-1}$ and $(X+E_1)(Y+E_2)^{-1}$.
\begin{lemma}
\label{lem:Mvariation}
Assume that $\sigma_{\min}(Y)\ge2\|E_2\|_2$, then
\[
\| XY^{-1} - (X+E_1)(Y+E_2)^{-1}\|_2 \le \frac{2\|X\|_2}{\sigma_{\min}^2(Y)}\|E_2\|_2 + \frac{2}{\sigma_{\min}(Y)}\|E_1\|_2.
\]
\end{lemma}
\begin{proof}
Applying Lemma \ref{lem:inversevariation},
\begin{align*}
	& \| XY^{-1} - (X+E_1)(Y+E_2)^{-1}\|_2 \\
\le\, & \| XY^{-1} - X(Y+E_2)^{-1}\|_2 + \| X(Y+E_2)^{-1} - (X+E_1)(Y+E_2)^{-1}\|_2 \\
\le\, & \|X\|_2\| Y^{-1} - (Y+E_2)^{-1}\|_2 + \|E_1\|_2\|(Y+E_2)^{-1}\|_2\\
\le\, & \frac{2\|X\|_2}{\sigma_{\min}^2(Y)}\|E_2\|_2 + \frac{2}{\sigma_{\min}(Y)}\|E_1\|_2
\end{align*}
\end{proof}


Note that $\nabla^2f_{\mu}(\psi) = \sum_{i=1}^{d} \kappa_i(\psi^{\top}A_i)^2A_iA_i^{\top} = AKD_{\psi}A^{\top}$,  where $D_{\psi} = \text{diag}\left((\psi^{\top}A_1)^2,\cdots, (\psi^{\top}A_d)^2\right)$. 
Thus, $\sigma_{\min}(\nabla^2f_{\mu}(\psi)) = \min_{v:\|v\|_2=1}\|\sum_{i=1}^{d} \kappa_i(\psi^{\top}A_i)^2A_iA_i^{\top}v\|_2$. 
\begin{lemma}
\label{lem:boundsigmaminnabla}
On the event $\Epsi$, $\sigma_{\max}(\nabla^2f_{\mu}(\psi)) \le L_u^2 \kappa_{\max}A^2_{(2,\max)}\sigma_{\max}^2(A)$, and
 $\sigma_{\min}(\nabla^2f_{\mu}(\psi)) \ge \frac{\sqrt{2\pi}}{2d} \ell^2\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)$.
\end{lemma}
\begin{proof}
Note that $\nabla^2f_{\mu}(\psi)$ is symmetric. 
For any unit vector $v$, $v^{\top}AD_{\psi}KA^{\top}v \ge \frac{\sqrt{2\pi}}{2d}\kappa_{\min} A^2_{(2,\min)}\|v^{\top}A\|_2^2 \ge \frac{\sqrt{2\pi}}{2d}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)$. Similar calculation for the maximum singular value.
\end{proof}

Lastly, we still need to bound $\|M - \widehat{M}\|_2$.
\begin{lemma}
\label{lem:Mvariation_alg}
Given that $\xi \le \frac{\sqrt{2\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)\ell^2}{8d^6 A_{(2,\max)}^2A_{\max}^2}$ and $T$  is large enough, but still polynomial in $\{L_\eta, C, \sigma_{\max}(A), L\}$, such that $P \le \frac{\sqrt{2\pi}}{8d}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)\ell^2$, then on the event $\Epsi$, 
\[ 
\|M - \widehat{M}\|_2 \le 2\left( \frac{2d^2A_{(2,\max)}^2\kappa_{\max}\sigma_{\max}^2(A)}{\pi\kappa^2_{\min}A^4_{(2,\min)}\sigma_{\min}^4(A)\ell^4} + 
\frac{\sqrt{2}d}{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)\ell^2}
\right)\left(d^5 A_{(2,\max)}^2A_{\max}^2\xi + P\right).
\]
\end{lemma}
\begin{proof}
Let $E_1 = \nabla^2 f_{\mu}(\phi) - \nabla^2 \widehat{f}(\phi)$ and $ E_2 = \nabla^2 f_{\mu}(\psi) - \nabla^2 \widehat{f}(\psi)$. Then $\|E_1\|_2 , \|E_2\|_2 \le L_u^2d^5 A_{(2,\max)}^2A_{\max}^2\xi + P$.
Note $\nabla^2f(\phi) = AKD_{\phi} A^{\top}$.
Given that $\xi \le  \frac{\sqrt{2\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)\ell^2}{8d^6 A_{(2,\max)}^2A_{\max}^2}$ and $P \le \frac{\sqrt{2\pi}}{8d}L_u^2\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)\ell^2$, the condition in Lemma \ref{lem:Mvariation} holds on the event $\Epsi$. 
Then apply Lemma \ref{lem:Mvariation} and \ref{lem:nablavariation}, we have
\begin{align*}
\|M - \widehat{M}\|_2 =\, & \|(\nabla^2 f(\phi))(\nabla^2f(\psi))^{-1} - (\nabla^2 \widehat{f}(\phi))(\nabla^2\widehat{f}(\psi))^{-1} \|_2 \\
\le \, &\frac{2\|\nabla^2 f(\phi)\|_2}{\sigma_{\min}^2(\nabla^2f(\psi))}\|E_2\|_2 + \frac{2}{\sigma_{\min}(\nabla^2f(\psi))}\|E_1\|_2 \\
\le \, & 2\left( \frac{2d^2A_{(2,\max)}^2\kappa_{\max}\sigma_{\max}^2(A)}{\pi\kappa^2_{\min}A^4_{(2,\min)}\sigma_{\min}^4(A)\ell^4} + 
\frac{\sqrt{2}d}{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)\ell^2}
\right)\left(d^5 A_{(2,\max)}^2A_{\max}^2\xi + P\right).
\end{align*}
\if0
Thus, 
\[ 
\|M - \widehat{M}\|_2 \le \frac{4d^7A_{(2,\max)}^4A_{\max}^2\kappa_{\max}\sigma_{\max}^2(A) + 2\sqrt{2\pi}d^6A_{(2,\max)}^2A_{\max}^2\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}{\pi\kappa^2_{\min}A^4_{(2,\min)}\sigma_{\min}^4(A)} \xi.
\]
\fi
\end{proof}
\begin{proof}[{\bf Proof of Theorem  \ref{thm:efficiency}}]
Let 
 \begin{align*}
Q = 2\left( \frac{2d^2A_{(2,\max)}^2\kappa_{\max}\sigma_{\max}^2(A)}{\pi\kappa^2_{\min}A^4_{(2,\min)}\sigma_{\min}^4(A)} + 
\frac{\sqrt{2}d}{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}
\right) \times \left(d^5 A_{(2,\max)}^2A_{\max}^2\xi + P\right)
 \end{align*}
 where $\xi$ is defined in Equation \eqref{eq:xi}.
 Note that P is proportional to $1/\sqrt{T}$, thus given large enough $T$ and small enough $\xi$, the following conditions hold:
 \begin{enumerate}
 \vspace{-3mm}
 \item $\gamma_A > 4\frac{\sigma_{\max}(A)}{\sigma_{\min}(A)} Q$
 \item $\min_{i,j:i\neq j} \|A_i - A_j\|_2 > \frac{8}{\gamma_A}\frac{\sigma_{\max}^2(A)}{\sigma_{\min}(A) } Q$;
 \item $\xi \le \frac{\sqrt{2\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}{8d^6 A_{(2,\max)}^2A_{\max}^2}$;
 \item $T$  is large enough, but still polynomial in $\{L_\eta, C, \sigma_{\max}(A), L\}$, such that $P \le \frac{\sqrt{2\pi}}{8d}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)$. 
  \end{enumerate}

Note that $M = \nabla^2f(\phi))(\nabla^2f(\psi))^{-1}$,  then by Lemma \ref{lem:Mvariation_alg}, $\|M-\widehat{M}\|_2 \le Q$.
Therefore, by lemma \ref{lem:eigenvectorvariation}, 
  \[
  \max_{1\le k\le d}\| c_1\widehat{A}_{\pi(k)} - A_k\|_2 \le 4 \frac{\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A)}\|M - \widehat{M} \|_2 \le 4 \frac{\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A)} Q. 
  \]
 %and 
 %\[
 %\sum_{k=1}^{d}\| c_1\widehat{A}_{\pi(k)} - A_k\|_2 \le 4d\frac{\sigma_{\max}^2(A)}{\gamma_A \sigma_{\min}(A)}\|M - \widehat{M} \|_2. 
% \]
 
\end{proof}

\subsection{Proof of Theorem \ref{thm:Modefficiency}}
\label{subsec:ProofModEff}
Note that $\nabla^2f(\psi) = AKD_{\psi}A^{\top}$. Thus $B = AK^{1/2}D_{\psi}^{1/2}R^{\top}$ for some orthonormal matrix $R$. 
We need to introduce some lemmas before we can prove the theorem. Without loss of generality, we assume $\kappa_i>0$ for $1\le i \le d$.
The following lemma shows the stability of the square root of matrix.
\begin{lemma}
\label{lem:matrixsquareroot}
Given two symmetric matrices $X$ and $\widehat{X} = X + E$, where $X = HH^{\top}$ and $\widehat{X} = \widehat{H}\widehat{H}^{\top}$, such that $|X^{-1}\|_2 \|E\|_2 < 1$, then every singular value of $H^{-1}\widehat{H}$ is bounded between $\sqrt{1- \|X^{-1}\|_2 \|E\|_2}$ and $\sqrt{1+ \|X^{-1}\|_2 \|E\|_2}$, 
and every singular value of $\widehat{H}^{-1}H$ is bounded between $\frac{1}{\sqrt{1 + \|X^{-1}\|_2 \|E\|_2}}$ and $\frac{1}{\sqrt{1 - \|X^{-1}\|_2 \|E\|_2}}$. 
\end{lemma}
\begin{proof}
For any unit vector $x$,
\begin{align*}
& x^{\top}H^{-1}\widehat{H}\widehat{H}^{\top}H^{-\top}x - x^{\top}x\\
& \quad = x^{\top}H^{-1}\left( \widehat{H}\widehat{H}^{\top} - HH^{\top}\right)H^{-\top}x \\
& \quad \le \|H^{-\top}x\|^2_2 \|E\|_2 \\
& \quad \le \|X^{-1}\|_2 \|E\|_2.
\end{align*}
Thus every singular value of $H^{-1}\widehat{H}$ is bounded between $\sqrt{1- \|X^{-1}\|_2 \|E\|_2}$ and $\sqrt{1+ \|X^{-1}\|_2 \|E\|_2}$, 
and every singular value of $\widehat{H}^{-1}H$ is bounded between $\frac{1}{\sqrt{1 + \|X^{-1}\|_2 \|E\|_2}}$ and $\frac{1}{\sqrt{1 - \|X^{-1}\|_2 \|E\|_2}}$.
\end{proof}
Applying Lemma \ref{lem:matrixsquareroot}, we can get the stability of $B$, as follows.
\begin{lemma}
\label{lem:BhatinverseB}
Given that $\xi \le \frac{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}{3\sqrt{2}d^6A_{(2,\max)}^2A_{\max}^2}$
(so $\bar{\xi} \le 1/3$), under the event $\Epsi$ there exists an orthonormal matrix $R^*$ such that 
\[
\|\widehat{B}^{-1}B - R^*\|_2 \le \bar{\xi}.
\]
\end{lemma}
\begin{proof}
Note that by Lemma \ref{lem:boundsigmaminnabla},  under the event $\Epsi$, $\|\nabla^2f(\psi)\|_2 \ge \frac{\sqrt{2\pi}}{2d}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)$. Thus,
\[
\|\left(\nabla^2f(\psi)\right)^{-1}\|_2 \|E\|_2 \le \frac{\sqrt{2}d^6A_{(2,\max)}^2A_{\max}^2}{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}\xi = \bar{\xi}.
\]
Then given $\xi \le \frac{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}{2\sqrt{2}d^6A_{(2,\max)}^2A_{\max}^2}$, $\bar{\xi} \le 1/3 < 1$. 
By Lemma \ref{lem:matrixsquareroot}, every singular value of $\widehat{B}^{-1}B$ is bounded between $\frac{1}{\sqrt{1 + \|\left(\nabla^2f(\psi)\right)^{-1}\|_2 \|E\|_2}}$ and $\frac{1}{\sqrt{1 - \|\left(\nabla^2f(\psi)\right)^{-1}\|_2 \|E\|_2}}$. 
Thus every singular value of $\widehat{B}^{-1}B$ is bounded between $\frac{1}{\sqrt{1+\bar{\xi}}}$ and $\frac{1}{\sqrt{1-\bar{\xi}}}$, i.e. there exist an orthonormal matrix $R^*$ such that 
\[
\|\widehat{B}^{-1}B - R^*\|_2 \le \max \left\{ \left|1-\frac{1}{\sqrt{1+\xi}}\right| , \left|\frac{1}{\sqrt{1-\xi}}-1\right| \right\} \le \bar{\xi},
\]
where the last inequality is by $\bar{\xi} \le 1/3$.
\end{proof}

Define $T_i$ by $T_i = G(B^{-\top}{R^*}^{\top}\phi_i) = A D_{\psi}^{-1}\Lambda_iA^{\top}$ for $i \in \{1,2\}$,
where $\Lambda_i = \text{diag}\left((\phi_i^{\top}R^*R_1)^2, \cdots, (\phi_i^{\top}R^*R_d)^2\right)$. 
Then, 
\begin{equation}
\label{eq:T}
M = A \Lambda_1 \Lambda_2^{-1} A^{-1} = A \Lambda A^{-1},
\end{equation}
where $\Lambda = \text{diag}\left((\frac{\phi_1^{\top}R^*R_1}{\phi_2^{\top}R^*R_1})^2, \cdots, (\frac{\phi_1^{\top}R^*R_d}{\phi_2^{\top}R^*R_d})^2\right)$. 

Similarly, we have the stability of the eigen-decomposition, as follows. 
\begin{lemma}
\label{lem:Teigenvectorvariation}
Denote $\widehat{M} = M+E$ be a perturbation of matrix $M$, where $M$ is defined in Equation \eqref{eq:T}. 
Assume $\widehat{T}$ has distinct eigenvalues. 
If $\gamma_R > 4 \frac{\sigma_{\max}^2(A)}{\sigma_{\min}(A) }\|E\|_2$ and $\min_{i,j:i\neq j} \|A_i - A_j\|_2 > \frac{8}{\gamma_R}\frac{\sigma_{\max}^2(A)}{\sigma_{\min}(A) } \|E\|_2$, then there exist a permutation $\pi$ and constants $\{c_1,\ldots,c_d\}$, such that for $1\le k\le d$
\[
\| c_k\widehat{A}_{\pi(k)} - A_k\|_2 \le \frac{4\sigma^2_{\max}(A)}{\gamma_R\sigma_{\min}(A)} \|E\|_2\,,
\]
where $\widehat{A}$ is the matrix of eigenvectors of $\widehat{M}$. 
\end{lemma}
\begin{proof}
The proof is similar to that of Lemma \ref{lem:eigenvectorvariation}.
\end{proof}
It still remains to bound $\|E\|_2$. In the event $\Ephi$, we take the orthogonal matrix $\tilde{R}$ as $R^*R$ in Equation \ref{eq:T} for the remaining of this paper.

\begin{lemma}
\label{lem:Binversenablavariation}
Given that $\xi \le \frac{\sqrt{\pi}\kappa_{\min}A^2_{(2,\min)}\sigma_{\min}^2(A)}{3\sqrt{2}d^6A_{(2,\max)}^2A_{\max}^2}$
(so $\bar{\xi} \le 1/3$), then on the event $\Epsi$ and $\Ephi$ for $\phi \in \{\phi_1, \phi_2\}$,
\[
\|G(B^{-\top}{R^*}^{\top}\phi) - \widehat{G}(\widehat{B}^{-\top}\phi)\|_2
\le 
\frac{3L_u^2d^7A^2_{\max}}{\pi\kappa_{\min}A^2_{(2,\min)}}\xi + \frac{2\sqrt{6}L_u^2d^2\sigma_{\max}^2(A)}{\pi A^2_{(2,\min)}}\bar{\xi}
\le \widehat{\xi}.
\]
\end{lemma}
\begin{proof}
Note that by Lemma \ref{lem:nablavariation} $\|\nabla^2 f(\psi) - \nabla^2 \widehat{f}(\psi)\|_2 \le d^5  A_{(2,\max)}^2A_{\max}^2\xi$, and 
\[
\|G(B^{-\top}R{^*}^{\top}\phi) - \widehat{G}(\widehat{B}^{-\top}\phi)\|_2
\le 
\|G(B^{-\top}{R^*}^{\top}\phi) - G(\widehat{B}^{-\top}\phi)\|_2
+ \|G(\widehat{B}^{-\top}\phi) - \widehat{G}(\widehat{B}^{-\top}\phi)\|_2.
\]

To Bound $\|G(\widehat{B}^{-\top}\phi) - \widehat{G}(\widehat{B}^{-\top}\phi)\|_2$, we will need the following properties which are straightforward based on Lemma \ref{lem:BhatinverseB}: 
under the event $\Epsi$ for $1\le i, j\le d$,
\begin{itemize}
\item $|\phi^{\top}\widehat{B}^{-1}A_i| \le \|\widehat{B}^{-1}B\|_2\|B^{-1}A_i\|_2\le
 \frac{L_u}{\sqrt{1-\bar{\xi}}} (K^{-1/2}D^{-1/2}_{\phi})_{ii} \le
 \frac{\sqrt{2}dL_u}{\sqrt{1-\bar{\xi}}\sqrt{\pi}\kappa_{\min}^{1/2}A_{(2,\min)}}$.
\end{itemize}
Thus for $1\le i, j\le d$,
\[
|(G_1(\widehat{B}^{-\top}\phi))_{i,j} - (\widehat{G_1}(\widehat{B}^{-\top}\phi))_{i,j}| \le
\frac{2L_u^2d^6A^2_{\max}}{(1-\bar{\xi})\pi\kappa_{\min}A^2_{(2,\min)}}D_4(\nu,\nu_t).
\]
Also note that for $1\le i, j\le d$,
\begin{itemize}
\item $|\int(\phi^{\top}\widehat{B}^{-1}x)x_i d\Prob{s}| 
\le L_u\int \|\widehat{B}^{-1}A\|_2\|s\|_2 |A_{i:}s| d\Prob{s}
\le \frac{\sqrt{2}L_ud^2C^2A_{(2,\max)}}{\sqrt{1-\bar{\xi}}\sqrt{\pi}\kappa_{\min}^{1/2}A_{(2,\min)}}$; 
\item $|(\widehat{B}^{-1}A)_{ij}| \le \frac{\sqrt{2}d}{\sqrt{1-\bar{\xi}}\sqrt{\pi}\kappa_{\min}^{1/2}A_{(2,\min)}}$;
\item $|\int(\phi^{\top}\widehat{B}^{-1}x)^2 d\Prob{s}|\le \frac{2L_u^2d^4C^2}{(1-\bar{\xi})\pi\kappa_{\min}A^2_{(2,\min)}}$.
\end{itemize}
Thus, similar to \ref{lem:nablavariation},
\[
|(G_2(\widehat{B}^{-\top}\phi))_{i,j} - (\widehat{G_2}(\widehat{B}^{-\top}\phi))_{i,j}| \le
\frac{4L_u^2d^6C^2A^2_{\max}}{(1-\bar{\xi})\pi\kappa_{\min}A^2_{(2,\min)}}D_2(\nu,\nu_t),
\]
and 
\[
|(G_3(\widehat{B}^{-\top}\phi))_{i,j} - (\widehat{G_3}(\widehat{B}^{-\top}\phi))_{i,j}| \le
\frac{4L_u^2d^6C^2A^2_{\max}}{(1-\bar{\xi})\pi\kappa_{\min}A^2_{(2,\min)}}D_2(\nu,\nu_t).
\]
Therefore for $1\le i,j\le d$,
\[
\left|\left(G(\widehat{B}^{-\top}\phi)\right)_{i,j} - \left(\widehat{G}(\widehat{B}^{-\top}\phi)\right)_{i,j}\right| 
\le
\frac{2L_u^2d^6A^2_{\max}}{(1-\bar{\xi})\pi\kappa_{\min}A^2_{(2,\min)}}\xi. 
\]
Thus, 
\begin{equation}
\label{eq:fBhatfhatBhat}
 \|G(\widehat{B}^{-\top}\phi) - \widehat{G}(\widehat{B}^{-\top}\phi)\|_2 \le 
\frac{3L_u^2d^7A^2_{\max}}{\pi\kappa_{\min}A^2_{(2,\min)}}\xi.
\end{equation}

On the other hand, 
\begin{align*}
\|G(B^{-\top}{R^*}^{\top}\phi_i) - G(\widehat{B}^{-\top}\phi_i)\|_2 
= & \, \|A D_{\psi}^{-1}\Lambda_iA^{\top}- A D_{\psi}^{-1}\widehat{\Lambda}_iA^{\top}\|_2 \\
\le & \, \|A\|^2_2 \|D_{\psi}^{-1}\|_2 \|\Lambda_i - \widehat{\Lambda}_i\|_2\\
\le & \, \frac{\sigma_{\max}^2(A)}{A^2_{(2,\min)}}\frac{4d^2L_u^2\bar{\xi}}{\pi\sqrt{1-\bar{\xi}}} \le \frac{2\sqrt{6}L_u^2d^2\sigma_{\max}^2(A)}{\pi A^2_{(2,\min)}}\bar{\xi},
\end{align*}
where $\widehat{\Lambda}_i = \text{diag}\left((\phi_i^{\top}\widehat{B}^{-1}BR_1)^2, \cdots, (\phi_i^{\top}\widehat{B}^{-1}BR_d)^2\right)$.
Thus,
\begin{equation}
\label{eq:fBfBhat}
\|G(B^{-\top}{R^*}^{\top}\phi) - G(\widehat{B}^{-\top}\phi)\|_2 \le \frac{2\sqrt{6}L_u^2d^2\sigma_{\max}^2(A)}{\pi A^2_{(2,\min)}}\bar{\xi}. 
\end{equation}

Combine Equation \eqref{eq:fBhatfhatBhat} and Equation \eqref{eq:fBfBhat},
\[
\|G(B^{-\top}{R^*}^{\top}\phi) - \widehat{G}(\widehat{B}^{-\top}\phi)\|_2
\le 
\frac{3L_u^2d^7A^2_{\max}}{\pi\kappa_{\min}A^2_{(2,\min)}}\xi + \frac{2\sqrt{6}L_u^2d^2\sigma_{\max}^2(A)}{\pi A^2_{(2,\min)}}\bar{\xi}.
\]
\end{proof}

\begin{lemma}
\label{lem:Tvariantion}
On the event $\Epsi$ and $\Ephi$, assume that $\widehat{\xi} \le \frac{l_l^2 A^2_{(2,\min)}}{2A^2_{(2,\max)}}$, then 
%\[
%\|T - \widehat{T}\|_2 \le %\frac{32\sqrt{2}d^5\kappa^{3/2}_{\max}A^6_{(2,\max)}}{\pi^{5/2}\kappa_{\min}A^4_{(2,\min)}} \sqrt{\widehat{\xi}} = Q.
%\]
\[
\|M - \widehat{M}\|_2 \le  \frac{128d^6A^6_{(2,\max)}}{\pi^3 A^6_{(2,\min)}}\widehat{\xi} = Q.
\]
\end{lemma}

\begin{proof}
On the event $\Epsi\cap\Ephi$,
\[
\sigma_{\min}(T_2) \ge \frac{l_l^2A^2_{(2,\min)}}{A^2_{(2,\max)}}; \quad \sigma_{\max}(T_2) \le \frac{L_u^2A^2_{(2,\max)}}{A^2_{(2,\min)}};  \quad \sigma_{\max}(T_1) \le \frac{L_u^2A^2_{(2,\max)}}{A^2_{(2,\min)}}. 
\]
Let $E_i = G(B^{-\top}{R^*}^{\top}\phi_i) - \widehat{G}(\widehat{B}^{-\top}\phi_i)$ for  $i\in\{1,2\}$. then by 
Lemma\ref{lem:Binversenablavariation} $\sigma_{\min}(T_2) \ge 2\|E_2\|_2$.
Apply Lemma \ref{lem:Mvariation},
\begin{align*}
\|M - \widehat{M}\|_2 \le &
\frac{2\|T_1\|_2}{\sigma^2_{\min}(T_2)}\|E_2\|_2 + \frac{2}{\sigma_{\min}(T_2)}\|E_1\|_2 \\
\le & \frac{4L_u^2A^6_{(2,\max)}}{l_l^4 A^6_{(2,\min)}}\widehat{\xi} = Q.
\end{align*}
\end{proof}
\begin{proof}[{\bf Proof of Theorem \ref{thm:Modefficiency}}]
Note that by Lemma \ref{lem:Tvariantion},
\[
\|\widehat{M} - M\|_2 \le Q.
\]
Then by Lemma \ref{lem:Teigenvectorvariation}, there exists a permutation $\pi$ and constants $\{c_1,\ldots,c_d\}$, such that for $1\le k\le d$,
\[
%\|c_k\widehat{R}_{\pi(k)} - (R^*R)_k\|_2 \le \frac{4}{\gamma_R} \|\widehat{T} - T\|_2\,,
\| c_k\widehat{A}_{\pi(k)} - A_k\|_2 \le \frac{4\sigma^2_{\max}(A)}{\gamma_R\sigma_{\min}(A)} \|\widehat{M} - M\|_2.
\]
\end{proof}

\subsection{Proofs of Lemma \ref{lem:dmin}, Lemma \ref{lem:CauchyGap} and Lemma \ref{lem:ConstantProb}}
\begin{proof}[Proof of Lemma \ref{lem:dmin}]
\if0
For a fixed constant $c \le A_{(2,\max)}$,
\begin{align*}
\Prob{\min_i \{|\psi^{\top}A_i|\} \ge c} = & \Prob{\cap_i\{\psi : |\psi^{\top}A_i|\ge c\}}\\
 \ge & \sum_i \Prob{|\psi^{\top}A_i|\ge c} - (d-1)
\end{align*}
Now note that sampling $\psi$ uniformly from the unit sphere is equivalent to sampling $\eta$ from a standard normal distribution and then let $\psi = \eta/ \|\eta\|_2$.
Also, let $\Prob{|\psi^{\top}A_i|\ge c} = \Prob{|\psi^{\top}R_i|\ge c/\|A_i\|_2}$ where $R_i$ is the normalized vector of $A_i$. 
Let $c' = c/\|A_i\|_2$. 
Thus, $ \Prob{|\psi^{\top}R_i|\ge c'} = \Prob{|\eta^{\top}R_i|/\|\eta\|_2\ge c'} \ge $
\fi
For a fixed constant $C_1 \le A_{(2,\max)}$, $\min_i \{|\psi^{\top}A_i|\} \ge C_1$ is equivalent to  $\cap_i G_i$, where $G_i$ is the set defined as $\{x: x^{\top}A_i\ge C_1\}$.  
Also note that for each $G_i$, let $C_1' = C_1/A_{(2,\min)}$ and $V_i = A_i/\|A_i\|_2$, then $G_i \supset G_i' = \{x: x^{\top}V_i\ge C_1'\}$.

Now we consider $\Prob{\cap_i G_i'}$. 
This probability is minimized when $V_i$s are orthogonal to each other. 
Thus, for any orthonormal matrix $R$, define $G_i'' = \{x: x^{\top}R_i\ge C_1'\}$, then 
\[
\Prob{\cap_i G_i'} \ge \Prob{\cap_i G_i''} = \Prob{|\psi^{\top}R| \ge C_1'} = \Prob{|\psi| \ge C_1'}.
\]
Note that $\Prob{|X|\ge C_1'} \ge 1- \frac{\sqrt{2}C_1'}{\sqrt{\pi}}$ for $X\sim N(0,1)$. Thus, picking $C_1 = \frac{\sqrt{\pi}A_{(2,\min)}}{\sqrt{2}d} \ell$ for any $0\le \ell \le 1$, 
\begin{equation}
\label{eq:GaussianLowerBound}
\Prob{|\psi| \ge C_1'} \ge (1- \frac{\sqrt{2}C_1'}{\sqrt{\pi}})^d = (1-\frac{\ell}{d})^d = \left(1- \frac{\ell}{d}\right)\left(1-\frac{\ell}{d}\right)^{d-1} \ge \left(1- \frac{\ell}{d}\right)\exp(-\ell).
\end{equation}
On the other hand, note that $\Prob{\|\psi\|_2 \le L_u} = \Prob{X \le L_u^2}$ where $X \sim \chi_d$.
Thus by Lemma 1 of \citep{laurent2000adaptive}, picking
\[
x = \left(\frac{\sqrt{2}}{2}L_u - \sqrt{d}\right)^2,
\]
then $L_u^2 \ge d+2\sqrt{dx}+2x$, and
\begin{equation}
\label{eq:ProbEpsi}
\Prob{\|\psi\|_2 \le L_u} = 1- \Prob{X\ge L_u^2} \ge 1- \Prob{X - d\ge 2\sqrt{dx} +2x} \ge 1-\exp(-x).
\end{equation}
Therefore, 
\begin{equation}
\label{eq:ProbEpsi2}
\Prob{\Epsi} \ge (1-\exp(-x))+\left(1- \frac{\ell}{d}\right)\exp(-\ell)-1 = \left(1- \frac{\ell}{d}\right)\exp(-\ell)-\exp(-x).
\end{equation}
\end{proof}

\begin{proof}[Proof of Lemma \ref{lem:CauchyGap}]
Since $\{Z_1,\ldots, Z_d\}$ are independent, we can calculate $\Prob{\EZ}$ by sequentially sampling $Z_i$s. 
Firstly, $\Prob{|Z_1|\ge C_2} \ge 1-\frac{2C_2}{\pi}$. 
Then $\Prob{Z_{k}: |Z_{k}|\ge C_2, |Z_{k+1}- Z_j|\ge C_2 \text{ for } j\le k-1} \ge 1-\frac{2kC_2}{\pi}$ for $2 \le k\le d$.
Therefore,
\begin{equation}
\label{eq:ProbEZ}
\Prob{\EZ} \ge (1-\frac{2C_2}{\pi})\times \ldots \times (1-\frac{2dC_2}{\pi}) \ge (1-\frac{2dC_2}{\pi})^d \ge \left(1- \frac{\ell}{d}\right)\exp(-\ell).
\end{equation}
\end{proof}

\begin{proof}[Prrof of Lemma \ref{lem:EventphiProb}]
For fix $\ell_l\le \frac{\sqrt{\pi}}{\sqrt{2}d}$, $L_u \ge \sqrt{2d}$ and an orthonormal matrix $R$, 
\[
\Prob{\Ephi} = \Prob{\|\phi_1\|_2\le L_u}\Prob{\|\phi_2\|_2\le L_u, \min_i \{|\phi_2^{\top}R_i|\} \ge \ell_l}.
\]
Denote the event $\|\phi_1\|_2\le L_u$ by $\Ephione$ and $\{\|\phi_2\|_2\le L_u, \min_i \{|\phi_2^{\top}R_i|\} \ge \ell_l\}$ by $\Ephitwo$. 

By Equation \eqref{eq:ProbEpsi}
\begin{equation}
\label{eq:ProbEphi1}
\Prob{\Ephione} \ge 1-\exp(-x).
\end{equation}
Similarly by Equation \eqref{eq:ProbEpsi2},
\begin{equation}
\label{eq:ProbEphi2}
\Prob{\Ephitwo} \ge (1-\exp(-x))+\left(1- \frac{\ell}{d}\right)\exp(-\ell)-1 = \left(1- \frac{\ell}{d}\right)\exp(-\ell)-\exp(-x).
\end{equation}

Combining Equation \eqref{eq:ProbEphi1} and \eqref{eq:ProbEphi2},
\[
\Prob{\Ephi} = (1-\exp(-x))(\left(1- \frac{\ell}{d}\right)\exp(-\ell)-\exp(-x)) \ge \left(1- \frac{\ell}{d}\right)\exp(-\ell) - 2\exp(-x).
\]
\end{proof}

\begin{proof}[Proof of Lemma \ref{lem:ConstantProb}]
Note that for $1\le \ell \le 1$, 
\[
\left(1- \frac{\ell}{d}\right)\exp(-\ell) \ge 1-\frac{d+1}{d}\ell.
\]
Combining Lemma \ref{lem:dmin}, \ref{lem:CauchyGap} and \ref{lem:EventphiProb}, given that $<1$,
\[
\Prob{\E} \ge \Prob{\Epsi} + \Prob{\EZ} + \Prob{\Ephi} -2 \ge 1- 3\frac{d+1}{d}\ell- 2\exp(-x)  
\]
Let $\ell = \frac{d}{d+1}\frac{\delta}{5}$ and $ x= \log(\frac{5}{\delta})$.
Then with probability $1-\delta$, 
\begin{itemize}
\item $\min_i |\psi^{\top}A_i| \ge \frac{\sqrt{\pi}A_{(2,\min)}}{5\sqrt{2}(d+1)} \delta$;
\item $\min_i \{|\phi_2^{\top}R_i|\} \ge \frac{\sqrt{\pi}}{5\sqrt{2}(d+1)}\delta$;
\item $\|\phi_1\|_2, \|\phi_2\|_2 \le \sqrt{2}\left(\sqrt{\log(\frac{5}{\delta})}+\sqrt{d}\right)$;
\item $\gamma_R \ge\frac{\pi^2}{100d^2(d+1)^2}\delta^2$.
\end{itemize}
\end{proof}

\subsection{Proof of Theorem \ref{thm:finalRes}}
Based on the analysis before this theorem, The first part of the theorem can be proved by replacing $\xi$ by $7C^2D_4(\nu,\nu_T)$ and applying Lemma \ref{lem:ConstantProb} and Theorem \ref{thm:Modefficiency}. 

It remains to prove that given large enough $T$, $D_4(\nu, \nu_T)$ is small enough. 
In particular, recall that the signal function $s$ is bounded by $C$. 
Thus any nomial with degree $\le 4$ will be bounded by $C^4$.
By Hoeffding's ineuqality, with probability at least $1-\delta$, 
\[
D_4(\nu, \nu_T) \le  C^4\sqrt{\frac{\log(1/\delta)}{2T}}.
\]
Therefore, there exists a polynomial such that given 
\[
T \ge \text{Poly}\left(C, \frac{1}{\delta}, d, \frac{1}{\min_{i,j:i\neq j}\|A_i - A_j\|_2}, \sigma_{\max}, 1/\sigma_{\min}, \kappa_{\max}, 1/\kappa_{\min}\right),
\]
with probability at least $1-2\delta$, there exists a permutation $\pi$ and constants $\{c_1,\ldots,c_d\}$, such that for $1\le k\le d$,
\[
\| c_k\widehat{A}_{\pi(k)} - A_k\|_2 \le \frac{7C^6\text{Poly}_3\sqrt{\log(1/\delta)}}{\sqrt{2T}}.
\]
